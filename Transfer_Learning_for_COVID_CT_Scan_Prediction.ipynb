{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM7yoUg09QeMxM66VPF12QL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations"
      ],
      "metadata": {
        "id": "dwVY9joOdhtB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ1b6-fGdgSy",
        "outputId": "b1271562-c1f7-42b2-e259-1c4d29c6035b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "torch version: 2.3.0+cu121\n",
            "torchvision version: 0.18.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHQbhOipdk9v",
        "outputId": "1885b109-e91c-4ff9-fb72-94631b1a364a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 39.59 MiB/s, done.\n",
            "Resolving deltas: 100% (2372/2372), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2kVbV2Faf_Rt",
        "outputId": "07f70d1c-cdb0-42a4-fef3-499bea75b807"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "KYhWnGgXgumo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"covid_ct_scan\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download COVID CT Scan Data\n",
        "    with open(data_path / \"covid_ct_scan.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/covid_ct_scan.zip\")\n",
        "        print(\"Downloading COVID CT Scan Data...\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip COVID CT Scan Data\n",
        "    with zipfile.ZipFile(data_path / \"covid_ct_scan.zip\", \"r\") as zip_ref:\n",
        "        print(\"Unzipping COVID CT Scan Data...\")\n",
        "        zip_ref.extractall(image_path)\n",
        "\n",
        "    # Remove .zip file\n",
        "    os.remove(data_path / \"covid_ct_scan.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy_X-ggOg0_R",
        "outputId": "3902920b-e864-4b4a-c4df-ca92b204d676"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "mDVqD_wIhRuc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Transform for torchvision.models"
      ],
      "metadata": {
        "id": "EhYgZxLmm-oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xrvXC98mz-J",
        "outputId": "ef3e770f-2d99-410f-9aa6-ff82474598ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet_B0_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FYpmYlinGDe",
        "outputId": "0263fba6-e89d-497d-89ae-5d307eb22152"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BICUBIC\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transforms, # perform same data transforms on our own data as the pretrained model\n",
        "                                                                               batch_size=32) # set mini-batch size to 32\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "OaS28Ne8n7A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing a Pre-trained Model"
      ],
      "metadata": {
        "id": "BO45uEbgoDft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NEW: Setup the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # .DEFAULT = best available weights\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQUua1UHoIv4",
        "outputId": "83dcee0a-b779-4fe9-b8b2-14302be98a3b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 139MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a summary using torchinfo\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QW_jWGWqNKq",
        "outputId": "2d42bea4-3981-4925-d5c0-ac1e57d758d6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n",
              "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n",
              "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
              "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
              "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
              "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
              "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
              "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
              "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
              "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     15,350               True\n",
              "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     31,290               True\n",
              "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     37,130               True\n",
              "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
              "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
              "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    126,004              True\n",
              "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
              "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
              "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      262,492              True\n",
              "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
              "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
              "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
              "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   True\n",
              "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      717,232              True\n",
              "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n",
              "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n",
              "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n",
              "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
              "├─Sequential (classifier)                                    [32, 1280]           [32, 1000]           --                   True\n",
              "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
              "│    └─Linear (1)                                            [32, 1280]           [32, 1000]           1,281,000            True\n",
              "============================================================================================================================================\n",
              "Total params: 5,288,548\n",
              "Trainable params: 5,288,548\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 12.35\n",
              "============================================================================================================================================\n",
              "Input size (MB): 19.27\n",
              "Forward/backward pass size (MB): 3452.35\n",
              "Params size (MB): 21.15\n",
              "Estimated Total Size (MB): 3492.77\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers in the \"features\" section of the model (the feature extractor) by setting requires_grad=False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "7RTqH_AUruo2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of class_names (one output unit for each class)\n",
        "output_shape = len(class_names)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ],
      "metadata": {
        "id": "ek679dRrwG_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}